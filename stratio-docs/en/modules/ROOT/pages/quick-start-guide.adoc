= Quick start guide

== EKS

=== Prerequisites

* For a user with the required privileges in AWS:
** Create a user for installation.
** Create a policy according to xref:attachment$stratio-eks-policy.json[_stratio-eks-policy.json_].
** Create a policy according to xref:attachment$stratio-aws-temp-policy.json[_stratio-aws-temp-policy.json_] (for provisioning only).
** Attach policies to the user.
** Create an access key.
* Private and public DNS zones created in AWS (optional).
* Customized infrastructure created on AWS (optional).
* Compose the cluster descriptor file.
** User credentials (_access++_++key_ and _secret++_++key_) and account data (region and _account++_++id_), which will be encrypted on first run.
** GitHub token for downloading templates (optional).
** Account data (region and _account++_++id_).
** Data of the infrastructure already created (optional).
** Management of DNS zones created (optional).
** ECR URL.
** External domain of the cluster.
** Enable logging in EKS per component (optional).
** Node groups.
** Information required for the _Stratio KEOS_ installation.

Regarding the _control-plane_, in the cluster descriptor you can indicate that it is a *managed _control-plane_* and the logs that you want to activate from it (API Server, _audit_, _authenticator_, _controller++_++manager_ and/or _scheduler_).

Likewise, *groups of _worker_ nodes* can be indicated with the following options:

* _name_: group name, cannot be repeated.
* _size_: instance type.
* _quantity_: number of _workers_ in the group.
* _min++_++size_: minimum number of nodes for autoscaling (optional).
* _max++_++size_: maximum number of nodes for autoscaling (optional).
* _labels_: node labels in Kubernetes (optional).
* _root++_++volume_: disk specifics (optional).
** _size_: size in GB (default: 30GB).
** _type_: disk type (default: gp2).
** _encrypted_: disk encryption (default: _false_).
* _ssh++_++key_: SSH key for node access (optional). Must exist in the provider.
* _spot_: indicates if the instance is of _spot_ type (optional).
* _node++_++image_: the image of the worker nodes (optional). The indicated image must exist and be compatible with EKS.
* _zone++_++distribution_: indicates whether the number of nodes must be balanced in the zones or not (default: _balanced_).
* _az_: zone of the worker's group (optional). If specified, only this one will be used for the whole group. This parameter overrides what is specified in _zone++_++distribution_.

NOTE: By default, the distribution of nodes will be done in zones a, b and c of the indicated region in a balanced way, therefore, the rest of the division by three of the number of nodes will be discarded. Example: if "quantity=7" is specified, only 2 nodes will be deployed in each of the zones.

==== _keos-installer_

In order to facilitate the installation of _Stratio KEOS_, in the provisioning process a functional _keos.yaml_ file is generated and ready to launch the installation. For this purpose, the version and flavour (_production_, _development_ or _minimal_) can be indicated in the cluster descriptor.

[source,yaml]
----
  keos:
    version: 1.0.2
    flavour: development
----

For any extra customization, the file must be modified before running the _keos-installer_.

===== Considerations

* If you use custom infrastructure, you must indicate the VPC and 3 subnets, one per region zone (a, b and c).
* The Kubernetes version indicated must be supported by EKS.
* The _worker++_++nodes_ group names cannot be repeated.

TIP: For more details, see the xref:ROOT:installation.adoc[installation guide].

==== Installation

You should run the provisioning and installation of the Kubernetes phase from a Linux machine with internet access and a Docker installed.

Once you have downloaded the `.tgz` file of the _cloud-provisioner_, proceed to unzip it and run it with the creation parameters:

[source,console]
----
$ tar xvzf cloud-provisioner-*tar.gz
$ sudo ./bin/cloud-provisioner create cluster --name <cluster_id> --descriptor cluster.yaml
Vault Password:
Creating temporary cluster "example-eks" ...
 âœ“ Ensuring node image (kindest/node:v1.27.0) ğŸ–¼
 âœ“ Building Stratio image (stratio-capi-image:v1.27.0) ğŸ“¸
 âœ“ Preparing nodes ğŸ“¦
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹ï¸
 âœ“ Installing CNI ğŸ”Œ
 âœ“ Installing StorageClass ğŸ’¾
 âœ“ Installing CAPx ğŸ–ï¸
 âœ“ Generating secrets file ğŸ“ğŸ—ï¸
 âœ“ Installing keos cluster operator ğŸ’»
 âœ“ Creating the workload cluster ğŸ’¥
 âœ“ Saving the workload cluster kubeconfig ğŸ“
 âœ“ Preparing nodes in workload cluster ğŸ“¦
 âœ“ Installing AWS LB controller in workload cluster âš–ï¸
 âœ“ Installing StorageClass in workload cluster ğŸ’¾
 âœ“ Enabling workload clusters self-healing ğŸ¥
 âœ“ Installing CAPx in workload cluster ğŸ–ï¸
 âœ“ Configuring Network Policy Engine in workload cluster ğŸš§
 âœ“ Installing cluster-autoscaler in workload cluster ğŸ—š
 âœ“ Installing keos cluster operator in workload cluster ğŸ’»
 âœ“ Creating cloud-provisioner Objects backup ğŸ—„ï¸
 âœ“ Moving the management role ğŸ—ï¸
 âœ“ Executing post-install steps ğŸ–ï¸
 âœ“ Generating the KEOS descriptor ğŸ“
 âœ“ Rotating and generating override_vars structure âš’ï¸

The cluster has been installed successfully. Please refer to the documents below on how to proceed:
1. Post-installation Stratio cloud-provisioner documentation
2. Stratio KEOS documentation
----

==== Next steps

At this point, you will have a Kubernetes cluster with the features indicated in the descriptor and you will be able to access the EKS API Server with the AWS CLI as indicated in https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html[the official documentation].

[source,console]
----
aws eks update-kubeconfig --region <region> --name <cluster_id> --kubeconfig ./<cluster_id>.kubeconfig

kubectl --kubeconfig ./<cluster_id>.kubeconfig get nodes
----

Here, the permissions of _clusterawsadm.json_ can be removed.

Next, proceed to deploy _Stratio KEOS_ *using _keos-installer_*.

== GKE

=== Prerequisites

* Enable the Kubernetes Engine API in GCP.
* A user with the necessary privileges in GCP:
** Create an _IAM Service Account_ with permissions defined in:
*** xref:attachment$stratio-gcp-permissions.list[stratio-gcp-permissions.list].
*** xref:attachment$stratio-gke-permissions.list[stratio-gke-permissions.list].
** Create a private key for the _IAM Service Account_ of type JSON and download it in a `<project_name>-<id>.json` file. This data will be used for the credentials requested in the cluster descriptor.
* Private and public DNS zones created in GCP (optional).
* Custom infrastructure created in GCP (optional).
* Composing the cluster descriptor file.
** User credentials (_private++_++key++_++id_, _private++_++key_, and _client++_++email_) and account data (refion and _project++_++id_), which will be encrypted on first run.
** GitHub token for template download (optional).
** Data of the infrastructure already created (optional).
** Management of DNS zones created (optional).
** _Docker registry_ data (URL, credentials).
** External domain of the cluster.
** _Control-plane_.
** Node groups.
** Information required for _Stratio KEOS_ installation.

NOTE: The installation *does not require* a custom image.

TIP: It is recommended to create a bastion to proceed with the installation.

==== Bastion requirements

- Have Docker installed (version 27.0.3 or higher).
- Have a local image: _stratio-capi-image:v1.27.0_.

==== _control-plane_

As for the _control-plane_, in the cluster descriptor you can indicate that it is a *managed _control-plane_* and the following specifications must be included::

* _cluster++_++network_ (mandatory): defines the cluster network.
** _private++_++cluster_ (mandatory): defines the _spec_ of the private cluster.
*** _enable++_++private++_++endpoint_ (mandatory/immutable; default: "true"): indicates whether the internal IP address of the _master_ is used as the endpoint of the cluster.
*** _control++_++plane++_++cidr++_++block_ (master-ipv4-cidr) (optional): is the IP range in CIDR notation to be used for the _master_ network. This range must not overlap with any other range in use within the cluster network. Applies when _enabled++_++private++_++nodes_ is "true" (default value) and must be a /28 subnet.
* _ip++_++allocation++_++policy_ (optional/immutable): represents the configuration options for the cluster GKE's IP allocation (if not specified, the GKE defaults will be used).
** _cluster++_++ipv4++_++cidr++_++block_: represents the range of IP addresses for the IPs of the pods of the cluster GKE (if not specified, the range with the default size will be chosen).
** _services++_++ipv4++_++cidr++_++block_: represents the range of IP addresses for the GKE cluster services IPs (if not specified, the range with the default size will be chosen).
** _cluster++_++secondary++_++range++_++name_: represents the name of the secondary range to be used for the CIDR block of the cluster GKE. The range will be used for the pods IP addresses and must be an existing secondary range associated with the cluster subnet.
** _services++_++secondary++_++range++_++name_: represents the name of the secondary range to be used for the services CIDR block. The range will be used for the services IPs and must be an existing secondary range associated with the cluster subnet.

NOTE: If IP ranges are already created, the specified names (services++_++secondary++_++range++_++name and cluster++_++secondary++_++range++_++name) must be used. If they do not exist, CIDR notation (services++_++ipv4++_++cidr++_++block and cluster++_++ipv4++_++cidr++_++block) must be used to create them, but both methods cannot be used simultaneously.

* _master++_++authorized++_++networks++_++config_ (optional/immutable): represents the cluster authorized networks configuration.
** _cidr++_++blocks_ (optional, since _gcp++_++public++_++cidrs++_++access++_++enabled_ is always "true"): list of CIDR blocks that are allowed to access the master.
*** _cidr++_++block_ (mandatory in case _cidr++_++blocks_ is present): IP range in CIDR notation that will be allowed to access the master.
*** _display++_++name_ (optional): name of the authorized network.
** _gcp++_++public++_++cidrs++_++access++_++enabled_ (default: "false", if _enable++_++private++_++endpoint_ is "true"): indicates whether access to Google Compute Engine public IP addresses is allowed.

NOTE: Enabling the authorized networking configuration will prevent all external traffic from accessing the Kubernetes master over HTTPS except for traffic from the specified CIDR blocks, Google Compute Engine public IPs, and Google Cloud services IPs.

* _monitoring++_++config_ (optional/immutable): defines the monitoring of the cluster.
** _enable++_++managed++_++prometheus_ (default: "false"): enables managed monitoring of the cluster with Prometheus.
* _logging++_++config_ (optional/immutable): defines the logging configuration of the cluster.
** _system++_++components_ (default: "false"): enables the _system_ component of logging.
** _workloads_ (default: "false"): enables the _workloads_ component of logging.

NOTE: Any modification of the above parameters will have no effect, they are only applied at cluster creation time.

==== _Worker_ nodes

In the cluster descriptor, _worker_ node groups can be indicated with the following options:

* _name_: group name, cannot be repeated.
* _size_: instance type.
* _quantity_: number of _workers_ in the group.
* _min++_++size_: minimum number of nodes for autoscaling (optional).
* _max++_++size_: maximum number of nodes for autoscaling (optional).
* _labels_: node labels in Kubernetes (optional).
* _taints_: _taints_ of the nodes in Kubernetes (optional).
* _root++_++volume_: disk specifics (optional).
** _size_: size in GB (default: 30GB).
** _type_: disk type (default: Managed).
* _zone++_++distribution_: indicates whether the number of nodes should be balanced in the zones or not (default: _balanced_).
* _az_: zone of the _workers_ group (optional). If specified, only this one will be used for the whole group. This parameter overrides what is specified in _zone++_++distribution_.

NOTE: By default, the distribution of nodes will be done in zones a, b, and c of the indicated region in a balanced way, therefore, the rest of the division by three of the number of nodes will be discarded. Example: if 'quantity=7' is specified, only 2 nodes will be deployed in each of the zones.

==== _keos-installer_

To facilitate the installation of _Stratio KEOS_, in the provisioning process a functional _keos.yaml_ file is generated and ready to launch the installation. For this purpose, the version and flavor (_production_, _development_, or _minimal_) can be indicated in the cluster descriptor.

[source,yaml]
----
  keos:
    version: 1.1.2
    flavour: development
----

For any extra customization, the file must be modified before running the _keos-installer_.

==== Considerations

* In case of using a custom infrastructure, the VPC and subnet of the region must be specified.
+
[source,yaml]
----
  networks:
    vpc_id: "vpc-name"
    subnets:
      - subnet_id: "subnet-name"
----

* Kubernetes version must be (1.28) and supported by GKE.
* _worker++_++nodes_ group names cannot be repeated.

TIP: For more details, see the xref:ROOT:installation.adoc[installation guide].

=== Installation

This phase (provisioning and installation of Kubernetes) should be run from the bastion machine.

Once the `.tgz` file of the _cloud-provisioner_ is downloaded, proceed to unzip it and run it with the creation parameters:

[source,console]
----
$ tar xvzf cloud-provisioner-*tar.gz
$ sudo ./bin/cloud-provisioner create cluster --name <cluster_id> --use-local-stratio-image --descriptor cluster.yaml
Vault Password:
Creating temporary cluster "example-gke" ...
 âœ“ Using local Stratio image (stratio-capi-image:v1.27.0) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹ï¸
 âœ“ Installing StorageClass ğŸ’¾
 âœ“ Installing Private CNI ğŸ–ï¸
 âœ“ Deleting local storage plugin ğŸ–ï¸
 âœ“ Installing CAPx ğŸ–ï¸
 âœ“ Generating secrets file ğŸ“ğŸ—ï¸
 âœ“ Installing keos cluster operator ğŸ’»
 âœ“ Creating the workload cluster ğŸ’¥
 âœ“ Saving the workload cluster kubeconfig ğŸ“
 âœ“ Preparing nodes in workload cluster ğŸ“¦
 âœ“ Enabling CoreDNS as DNS server ğŸ“¡
 âœ“ Installing CAPx in workload cluster ğŸ–ï¸
 âœ“ Installing StorageClass in workload cluster ğŸ’¾
 âœ“ Enabling workload cluster's self-healing ğŸ¥
 âœ“ Configuring Network Policy Engine in workload cluster ğŸš§
 âœ“ Installing keos cluster operator in workload cluster ğŸ’»
 âœ“ Creating cloud-provisioner Objects backup ğŸ—„ï¸
 âœ“ Moving the management role ğŸ—ï¸
 âœ“ Executing post-install steps ğŸ–ï¸
 âœ“ Generating the KEOS descriptor ğŸ“
 âœ“ Rotating and generating override_vars structure âš’ï¸
The cluster has been installed successfully. Please refer to the documents below on how to proceed:
1. Post-installation Stratio cloud-provisioner documentation.
2. Stratio KEOS documentation.
----

=== Next steps

At this point, there will be a Kubernetes cluster with the features indicated in the descriptor, and the _API Server_ can be accessed with the _kubeconfig_ generated in the current directory (_.kube/config_):

[source,console]
----
kubectl --kubeconfig .kube/config get nodes
----

Next, proceed to deploy _Stratio KEOS_ *using _keos-installer_*.

== Azure unmanaged

=== Prerequisites

* Users with the necessary privileges in Azure:
** Create a _Managed Identity_ with the roles: _Contributor_, _AcrPull_ (on the ACR of the cluster, optional) and _Managed Identity Operator_. The reference of this identity (Resource ID) will be used in the cluster descriptor (format _/subscriptions/<subscription_id>/resourcegroups/<resource_group_name>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<identity_name>_).
** Create an _App registration_ (will create an _Enterprise application_) and generate a _client secret_. The _client secret_ value and its _Secret ID_ will be used for the credentials requested in the cluster descriptor.
* Private and public DNS zones created in Azure (optional).
* Customized infrastructure created in Azure (optional).
* Compose the cluster descriptor file.
** User credentials (_client++_++id_ and _client++_++secret_) and account data (_subscription++_++id_ and _tenant++_++id_), which will be encrypted on first run.
** GitHub token for template download (optional).
** Data of the already created infrastructure (optional).
** Management of DNS zones created (optional).
** Docker registry data (URL, credentials).
** External domain of the cluster.
** _control-plane_.
** Node groups.
** Information required for the _Stratio KEOS_ installation.

NOTE: The installation requires a custom image with parameters needed for Elasticsearch.

==== _control-plane_ nodes

For this provider, the _control-plane_ will be deployed in VMs, therefore, the following options can be configured:

* _highly++_++available_: defines whether the _control-plane_ will have high availability (default: _true_).
* _managed_: indicates that it is a _control-plane_ in VMs.
* _size_: instance type.
* _node++_++image_: image of the nodes of the _control-plane_. The indicated image must exist in the account.
* _root++_++volume_: disk particularities (optional).
** _size_: size in GB (default: 30GB).
** _type_: disk type (default: Standard_LRS).

==== _Worker_ nodes

In the cluster descriptor, groups of _worker_ nodes can be indicated with the following options:

* _name_: group name, cannot be repeated.
* _size_: instance type.
* _quantity_: number of _workers_ in the group.
* _min++_++size_: minimum number of nodes for autoscaling (optional).
* _max++_++size_: maximum number of nodes for autoscaling (optional).
* _labels_: node labels in Kubernetes (optional).
* _root++_++volume_: disk specifics (optional).
** _size_: size in GB (default: 30GB).
** _type_: disk type (default: Standard_LRS).
* _ssh++_++key_: SSH key for node access (optional). Must exist in the provider.
* _spot_: indicates if the instance is of _spot_-type (optional).
* _node++_++image_: the image of the _worker_ nodes. The indicated image must exist in the account.
* _zone++_++distribution_: indicates whether the number of nodes must be balanced in the zones or not (default: _balanced_).
* _az_: zone of the _workers_ group (optional). If specified, only this one will be used for the whole group. This parameter overrides what is specified in _zone++_++distribution_.

NOTE: By default, the distribution of nodes will be done in zones a, b and c of the indicated region in a balanced way, therefore, the rest of the division by three of the number of nodes will be discarded. Example: if 'quantity=7' is specified, only 2 nodes will be deployed in each of the zones.

==== _keos-installer_

In order to facilitate the installation of _Stratio KEOS_, in the provisioning process a functional _keos.yaml_ file is generated and ready to launch the installation. For this purpose, the version and flavour (_production_, _development_ or _minimal_) can be indicated in the cluster descriptor.

[source,yaml]
----
  keos:
    version: 1.0.2
    flavour: development
----

For any extra customization, the file must be modified before running the _keos-installer_.

==== Considerations

* If you use custom infrastructure, you must indicate the VPC and 3 subnets, one per region zone (a, b and c).
* The configured Kubernetes version must be the one supported in the indicated images (optional).
* The names of the _worker++_++nodes_ groups cannot be repeated.

TIP: For more details, see the xref:ROOT:installation.adoc[installation guide].

=== Installation

You should run the provisioning and installation of the Kubernetes phase from a Linux machine with internet access and a Docker installed.

Once you have downloaded the `.tgz` file of the _cloud-provisioner_, proceed to unzip it and run it with the creation parameters:

[source,console]
----
$ tar xvzf cloud-provisioner-*tar.gz
$ sudo ./bin/cloud-provisioner create cluster --name <cluster_id> --descriptor cluster.yaml
Vault Password:
Creating temporary cluster "example-azure" ...
 âœ“ Ensuring node image (kindest/node:v1.27.0) ğŸ–¼
 âœ“ Building Stratio image (stratio-capi-image:v1.27.0) ğŸ“¸
 âœ“ Preparing nodes ğŸ“¦
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹ï¸
 âœ“ Installing CNI ğŸ”Œ
 âœ“ Installing StorageClass ğŸ’¾
 âœ“ Installing CAPx ğŸ–ï¸
 âœ“ Generating secrets file ğŸ“ğŸ—ï¸
 âœ“ Installing keos cluster operator ğŸ’»
 âœ“ Creating the workload cluster ğŸ’¥
 âœ“ Saving the workload cluster kubeconfig ğŸ“
 âœ“ Installing cloud-provider in workload cluster â˜ï¸
 âœ“ Installing Calico in workload cluster ğŸ”Œ
 âœ“ Installing CSI in workload cluster ğŸ’¾
 âœ“ Preparing nodes in workload cluster ğŸ“¦
 âœ“ Installing StorageClass in workload cluster ğŸ’¾
 âœ“ Enabling workload clusters self-healing ğŸ¥
 âœ“ Installing CAPx in workload cluster ğŸ–ï¸
 âœ“ Installing cluster-autoscaler in workload cluster ğŸ—š
 âœ“ Installing keos cluster operator in workload cluster ğŸ’»
 âœ“ Creating cloud-provisioner Objects backup ğŸ—„ï¸
 âœ“ Moving the management role ğŸ—ï¸
 âœ“ Executing post-install steps ğŸ–ï¸
 âœ“ Generating the KEOS descriptor ğŸ“

The cluster has been installed successfully. Please refer to the documents below on how to proceed:
1. Post-installation Stratio cloud-provisioner documentation
2. Stratio KEOS documentation
----

=== Next steps

At this point, you will have a Kubernetes cluster with the features indicated in the descriptor and you will be able to access the API Server with the _kubeconfig_ generated in the current directory (_.kube/config_):

[source,console]
----
kubectl --kubeconfig .kube/config get nodes
----

Next, proceed to deploy _Stratio KEOS_ *using _keos-installer_*.

=== Next steps

At this point, you will have a Kubernetes cluster with the features indicated in the descriptor and you will be able to access the API Server with the _kubeconfig_ generated in the current directory (_.kube/config_):

[source,console]
----
kubectl --kubeconfig .kube/config get nodes
----

Next, proceed to deploy _Stratio KEOS_ *using _keos-installer_*.
